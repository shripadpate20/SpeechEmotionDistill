üéôÔ∏è Speech Emotion Recognition with Knowledge Distillation

This project explores knowledge distillation techniques to improve the efficiency of emotion recognition from speech. A larger teacher model is used to guide a lightweight student model for better performance with lower computational cost. The CREMA-D dataset is used for training and evaluation.
